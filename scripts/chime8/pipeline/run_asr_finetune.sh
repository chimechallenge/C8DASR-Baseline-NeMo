NEMO_ROOT=${PWD}/../../../ # path to your NeMo root
export PYTHONPATH=$NEMO_ROOT:$PYTHONPATH

HARD_STRATEGY='replicate'
MAX_STEPS=35000
WARMUP_STEPS=1000
VAL_CHECK_INTERVAL=1.0
CHECK_VAL_EVERY_N_EPOCHS=3
TRAIN_BATCH_SIZE=4
EVAL_BATCH_SIZE=2
ACCUMULATE_GRAD_BATCHES=1
PRECISION=32
STRATEGY='ddp'
GRAD_CLIP_VAL=1
SAVE_TOP_K=5

# SEG LENGTHS
TRAIN_MAX_DURATION=20
TRAIN_MIN_DURATION=0

EVAL_MAX_DURATION=20
EVAL_MIN_DURATION=0

#CONFORMER PARAMS
D_MODEL=1024
N_LAYERS=24
CONV_SIZE=9
SAMPLING_FACTOR=8
N_HEADS=8
TIME_MASKS=10
TIME_WIDTH=0.05
VOCAB_SIZE=1024
ENCODING=bpe # char or bpe
TOKENIZER_TYPE=bpe #bpe or wpe
ENCODER_XSCALING=true

ATT_DROPOUT=0.1
EMB_DROPOUT=0.0

# TRANSDUCER PARAMS
START_END_TOKEN=false
DECODER_N_LAYERS=2
DECODER_SIZE=640
FUSED_BATCH_SIZE=2
VAR_STD=0
VAR_START=0
RNNT_DROPOUT=0.2
EMIT_LAMBDA=0

# OPT and SCHED
OPT=adamw
PEAK_LR=0.0001
LR_SCHEDULE=CosineAnnealing
if [ "$LR_SCHEDULE" = "NoamAnnealing" ]; then
    LR=$(echo "scale=9; $PEAK_LR * sqrt($D_MODEL) * sqrt($WARMUP_STEPS)" | bc)
else
    LR=$PEAK_LR
fi
MIN_LR=1e-5
WD=1e-2

PROJECT_NAME=chime8-asr-fc-conformer_rnnt
EXP_NAME=fc_rnnt_prec${PRECISION}_layers${N_LAYERS}_heads${N_HEADS}_conv${CONV_SIZE}_d${D_MODEL}_dlayers${DECODER_N_LAYERS}_dsize${DECODER_SIZE}_bs${GLOBAL_BATCH_SIZE}_${OPT}_${LR_SCHEDULE}_lr${PEAK_LR}_wd${WD}_spunigram${VOCAB_SIZE}


TOKENIZER=/tokenizers/librispeech/librispeech_tokenizer_spe_unigram_v${VOCAB_SIZE}/
INIT_MODEL=stt_en_fastconformer_transducer_xlarge.nemo


SCRIPT_NAME=${NEMO_ROOT}/examples/asr/speech_to_text_finetune.py


